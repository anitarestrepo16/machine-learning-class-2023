{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning - Mini Project 1 Solutions\n",
    "## PPHA 30545 - Professor Clapp\n",
    "### Winter 2023\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np \n",
    "from sklearn.linear_model import LinearRegression as lm\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.formula.api as smf\n",
    "from statsmodels.stats.anova import anova_lm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "acs_data = pd.read_csv('usa_00001.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the data \n",
    "### 3.1. Familiarizing with the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>STRATA</th>\n",
       "      <th>GQ</th>\n",
       "      <th>PERNUM</th>\n",
       "      <th>PERWT</th>\n",
       "      <th>...</th>\n",
       "      <th>RACED</th>\n",
       "      <th>HISPAN</th>\n",
       "      <th>HISPAND</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>EDUCD</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>EMPSTATD</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>VETSTAT</th>\n",
       "      <th>VETSTATD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021</td>\n",
       "      <td>202101</td>\n",
       "      <td>1902</td>\n",
       "      <td>2021010114983</td>\n",
       "      <td>5304.0</td>\n",
       "      <td>2021000019021</td>\n",
       "      <td>160001</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>5304.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10000</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021</td>\n",
       "      <td>202101</td>\n",
       "      <td>2994</td>\n",
       "      <td>2021000021366</td>\n",
       "      <td>25116.0</td>\n",
       "      <td>2021000029941</td>\n",
       "      <td>270201</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>29172.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1000</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021</td>\n",
       "      <td>202101</td>\n",
       "      <td>3150</td>\n",
       "      <td>2021000032187</td>\n",
       "      <td>14664.0</td>\n",
       "      <td>2021000031501</td>\n",
       "      <td>100001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14664.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>21000</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021</td>\n",
       "      <td>202101</td>\n",
       "      <td>3306</td>\n",
       "      <td>2021000042884</td>\n",
       "      <td>2964.0</td>\n",
       "      <td>2021000033061</td>\n",
       "      <td>250001</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3120.0</td>\n",
       "      <td>...</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>24000</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2021</td>\n",
       "      <td>202101</td>\n",
       "      <td>3618</td>\n",
       "      <td>2021000063494</td>\n",
       "      <td>13260.0</td>\n",
       "      <td>2021000036181</td>\n",
       "      <td>130301</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>13104.0</td>\n",
       "      <td>...</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>114</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>85000</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEAR  SAMPLE  SERIAL       CBSERIAL     HHWT        CLUSTER  STRATA  GQ  \\\n",
       "0  2021  202101    1902  2021010114983   5304.0  2021000019021  160001   4   \n",
       "1  2021  202101    2994  2021000021366  25116.0  2021000029941  270201   1   \n",
       "2  2021  202101    3150  2021000032187  14664.0  2021000031501  100001   1   \n",
       "3  2021  202101    3306  2021000042884   2964.0  2021000033061  250001   1   \n",
       "4  2021  202101    3618  2021000063494  13260.0  2021000036181  130301   1   \n",
       "\n",
       "   PERNUM    PERWT  ...  RACED  HISPAN  HISPAND  EDUC  EDUCD  EMPSTAT  \\\n",
       "0       1   5304.0  ...    100       0        0     7     71        1   \n",
       "1       2  29172.0  ...    200       0        0     6     63        1   \n",
       "2       1  14664.0  ...    100       0        0     6     63        1   \n",
       "3       1   3120.0  ...    200       0        0     4     40        1   \n",
       "4       1  13104.0  ...    100       0        0    11    114        1   \n",
       "\n",
       "   EMPSTATD  INCWAGE  VETSTAT  VETSTATD  \n",
       "0        10    10000        1        11  \n",
       "1        10     1000        1        11  \n",
       "2        10    21000        1        11  \n",
       "3        10    24000        1        11  \n",
       "4        10    85000        1        11  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>SAMPLE</th>\n",
       "      <th>SERIAL</th>\n",
       "      <th>CBSERIAL</th>\n",
       "      <th>HHWT</th>\n",
       "      <th>CLUSTER</th>\n",
       "      <th>STRATA</th>\n",
       "      <th>GQ</th>\n",
       "      <th>PERNUM</th>\n",
       "      <th>PERWT</th>\n",
       "      <th>...</th>\n",
       "      <th>RACED</th>\n",
       "      <th>HISPAN</th>\n",
       "      <th>HISPAND</th>\n",
       "      <th>EDUC</th>\n",
       "      <th>EDUCD</th>\n",
       "      <th>EMPSTAT</th>\n",
       "      <th>EMPSTATD</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>VETSTAT</th>\n",
       "      <th>VETSTATD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8556.0</td>\n",
       "      <td>8556.0</td>\n",
       "      <td>8.556000e+03</td>\n",
       "      <td>8.556000e+03</td>\n",
       "      <td>8556.000000</td>\n",
       "      <td>8.556000e+03</td>\n",
       "      <td>8.556000e+03</td>\n",
       "      <td>8556.000000</td>\n",
       "      <td>8556.000000</td>\n",
       "      <td>8556.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8556.000000</td>\n",
       "      <td>8556.000000</td>\n",
       "      <td>8556.000000</td>\n",
       "      <td>8556.000000</td>\n",
       "      <td>8556.000000</td>\n",
       "      <td>8556.0</td>\n",
       "      <td>8556.000000</td>\n",
       "      <td>8556.000000</td>\n",
       "      <td>8556.000000</td>\n",
       "      <td>8556.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>202101.0</td>\n",
       "      <td>7.208495e+05</td>\n",
       "      <td>2.021001e+12</td>\n",
       "      <td>16262.124825</td>\n",
       "      <td>2.021007e+12</td>\n",
       "      <td>4.677905e+05</td>\n",
       "      <td>1.063114</td>\n",
       "      <td>1.694016</td>\n",
       "      <td>16624.410940</td>\n",
       "      <td>...</td>\n",
       "      <td>261.667017</td>\n",
       "      <td>0.326905</td>\n",
       "      <td>34.298621</td>\n",
       "      <td>7.886746</td>\n",
       "      <td>81.183263</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.080295</td>\n",
       "      <td>60561.317204</td>\n",
       "      <td>1.041608</td>\n",
       "      <td>11.401823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.206382e+05</td>\n",
       "      <td>1.391498e+06</td>\n",
       "      <td>13530.554382</td>\n",
       "      <td>4.206382e+06</td>\n",
       "      <td>9.381907e+05</td>\n",
       "      <td>0.427287</td>\n",
       "      <td>0.953687</td>\n",
       "      <td>13964.445118</td>\n",
       "      <td>...</td>\n",
       "      <td>268.836697</td>\n",
       "      <td>0.913734</td>\n",
       "      <td>98.078562</td>\n",
       "      <td>2.352989</td>\n",
       "      <td>23.529964</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.491879</td>\n",
       "      <td>74458.147968</td>\n",
       "      <td>0.199704</td>\n",
       "      <td>1.803708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>202101.0</td>\n",
       "      <td>1.902000e+03</td>\n",
       "      <td>2.021000e+12</td>\n",
       "      <td>312.000000</td>\n",
       "      <td>2.021000e+12</td>\n",
       "      <td>1.000100e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>156.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>202101.0</td>\n",
       "      <td>3.517320e+05</td>\n",
       "      <td>2.021000e+12</td>\n",
       "      <td>7956.000000</td>\n",
       "      <td>2.021004e+12</td>\n",
       "      <td>9.001700e+04</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8112.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>20000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>202101.0</td>\n",
       "      <td>7.195800e+05</td>\n",
       "      <td>2.021001e+12</td>\n",
       "      <td>12480.000000</td>\n",
       "      <td>2.021007e+12</td>\n",
       "      <td>2.200270e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>12792.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>42000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>202101.0</td>\n",
       "      <td>1.090470e+06</td>\n",
       "      <td>2.021001e+12</td>\n",
       "      <td>19968.000000</td>\n",
       "      <td>2.021011e+12</td>\n",
       "      <td>4.103360e+05</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20280.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>101.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>75000.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>202101.0</td>\n",
       "      <td>1.440846e+06</td>\n",
       "      <td>2.021010e+12</td>\n",
       "      <td>175968.000000</td>\n",
       "      <td>2.021014e+12</td>\n",
       "      <td>5.930851e+06</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>175812.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>990.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>498.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>682000.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         YEAR    SAMPLE        SERIAL      CBSERIAL           HHWT  \\\n",
       "count  8556.0    8556.0  8.556000e+03  8.556000e+03    8556.000000   \n",
       "mean   2021.0  202101.0  7.208495e+05  2.021001e+12   16262.124825   \n",
       "std       0.0       0.0  4.206382e+05  1.391498e+06   13530.554382   \n",
       "min    2021.0  202101.0  1.902000e+03  2.021000e+12     312.000000   \n",
       "25%    2021.0  202101.0  3.517320e+05  2.021000e+12    7956.000000   \n",
       "50%    2021.0  202101.0  7.195800e+05  2.021001e+12   12480.000000   \n",
       "75%    2021.0  202101.0  1.090470e+06  2.021001e+12   19968.000000   \n",
       "max    2021.0  202101.0  1.440846e+06  2.021010e+12  175968.000000   \n",
       "\n",
       "            CLUSTER        STRATA           GQ       PERNUM          PERWT  \\\n",
       "count  8.556000e+03  8.556000e+03  8556.000000  8556.000000    8556.000000   \n",
       "mean   2.021007e+12  4.677905e+05     1.063114     1.694016   16624.410940   \n",
       "std    4.206382e+06  9.381907e+05     0.427287     0.953687   13964.445118   \n",
       "min    2.021000e+12  1.000100e+04     1.000000     1.000000     156.000000   \n",
       "25%    2.021004e+12  9.001700e+04     1.000000     1.000000    8112.000000   \n",
       "50%    2.021007e+12  2.200270e+05     1.000000     1.000000   12792.000000   \n",
       "75%    2.021011e+12  4.103360e+05     1.000000     2.000000   20280.000000   \n",
       "max    2.021014e+12  5.930851e+06     4.000000     9.000000  175812.000000   \n",
       "\n",
       "       ...        RACED       HISPAN      HISPAND         EDUC        EDUCD  \\\n",
       "count  ...  8556.000000  8556.000000  8556.000000  8556.000000  8556.000000   \n",
       "mean   ...   261.667017     0.326905    34.298621     7.886746    81.183263   \n",
       "std    ...   268.836697     0.913734    98.078562     2.352989    23.529964   \n",
       "min    ...   100.000000     0.000000     0.000000     0.000000     2.000000   \n",
       "25%    ...   100.000000     0.000000     0.000000     6.000000    63.000000   \n",
       "50%    ...   100.000000     0.000000     0.000000     7.000000    71.000000   \n",
       "75%    ...   359.000000     0.000000     0.000000    10.000000   101.000000   \n",
       "max    ...   990.000000     4.000000   498.000000    11.000000   116.000000   \n",
       "\n",
       "       EMPSTAT     EMPSTATD        INCWAGE      VETSTAT     VETSTATD  \n",
       "count   8556.0  8556.000000    8556.000000  8556.000000  8556.000000  \n",
       "mean       1.0    10.080295   60561.317204     1.041608    11.401823  \n",
       "std        0.0     0.491879   74458.147968     0.199704     1.803708  \n",
       "min        1.0    10.000000       0.000000     1.000000    11.000000  \n",
       "25%        1.0    10.000000   20000.000000     1.000000    11.000000  \n",
       "50%        1.0    10.000000   42000.000000     1.000000    11.000000  \n",
       "75%        1.0    10.000000   75000.000000     1.000000    11.000000  \n",
       "max        1.0    15.000000  682000.000000     2.000000    20.000000  \n",
       "\n",
       "[8 rows x 26 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2. For our analysis, we'll need to use the codebook we saved to clean and create a few variables:\n",
    "#### a) Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a continuous education variable\n",
    "crosswalk = pd.read_csv('PPHA_30545_MP01-Crosswalk')\n",
    "crosswalk = crosswalk.set_index('educd').T\n",
    "\n",
    "acs_data['EDUCDC'] = acs_data['EDUCD']\n",
    "acs_data = acs_data.replace({'EDUCDC': crosswalk})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b) Dummy variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i. High school diploma\n",
    "acs_data['hsdip'] = ((acs_data['EDUCDC'] >= 12) & (acs_data['EDUCDC'] < 16)).astype(int)\n",
    "# ii. College degree\n",
    "acs_data['coldip'] = (acs_data['EDUCDC'] >= 16).astype(int)\n",
    "# iii. white\n",
    "acs_data['White'] = np.where(acs_data['RACE'] == 1, 1, 0)\n",
    "# iv. black\n",
    "acs_data['Black'] = np.where(acs_data['RACE'] == 2, 1, 0)\n",
    "# v. hispanic\n",
    "acs_data['hispanic'] = ((acs_data['HISPAN'] != 0) & (acs_data['HISPAN'] != 9)).astype(int)\n",
    "# vi. married\n",
    "acs_data['married'] = ((acs_data['MARST'] == 1) | (acs_data['MARST'] == 2)).astype(int)\n",
    "# vii. female\n",
    "acs_data['female'] = (acs_data['SEX'] == 2).astype(int)\n",
    "# viii. veteran\n",
    "acs_data['VET'] = np.where(acs_data['VETSTAT'] == 2, 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c) Interaction terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['hsdip', 'coldip']:\n",
    "    acs_data[var + '_inter_educdc'] = acs_data[var]*acs_data['EDUCDC']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d) Create the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop observations with zero income wage\n",
    "incwage_zero_index = acs_data[acs_data['INCWAGE'] == 0].index\n",
    "acs_data.drop(incwage_zero_index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i. Age squared\n",
    "acs_data['AGE_SQ'] = np.power(acs_data['AGE'], 2)\n",
    "# ii. log of income\n",
    "acs_data['INCWAGE_log'] = np.log(acs_data['INCWAGE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Data Analysis\n",
    "### 1. Compute descriptive statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>INCWAGE</th>\n",
       "      <th>INCWAGE_log</th>\n",
       "      <th>EDUCDC</th>\n",
       "      <th>female</th>\n",
       "      <th>AGE</th>\n",
       "      <th>AGE_SQ</th>\n",
       "      <th>White</th>\n",
       "      <th>Black</th>\n",
       "      <th>hispanic</th>\n",
       "      <th>married</th>\n",
       "      <th>NCHILD</th>\n",
       "      <th>VET</th>\n",
       "      <th>hsdip</th>\n",
       "      <th>coldip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8143.0</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "      <td>8143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>63632.890826</td>\n",
       "      <td>10.561771</td>\n",
       "      <td>14.231610</td>\n",
       "      <td>0.481027</td>\n",
       "      <td>41.526096</td>\n",
       "      <td>1898.076753</td>\n",
       "      <td>0.663269</td>\n",
       "      <td>0.081051</td>\n",
       "      <td>0.162348</td>\n",
       "      <td>0.533833</td>\n",
       "      <td>0.823898</td>\n",
       "      <td>0.041754</td>\n",
       "      <td>0.541815</td>\n",
       "      <td>0.406607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>75031.705812</td>\n",
       "      <td>1.133858</td>\n",
       "      <td>3.023473</td>\n",
       "      <td>0.499671</td>\n",
       "      <td>13.178825</td>\n",
       "      <td>1104.537492</td>\n",
       "      <td>0.472621</td>\n",
       "      <td>0.272931</td>\n",
       "      <td>0.368792</td>\n",
       "      <td>0.498885</td>\n",
       "      <td>1.151690</td>\n",
       "      <td>0.200038</td>\n",
       "      <td>0.498279</td>\n",
       "      <td>0.491230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>3.401197</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>324.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>24000.000000</td>\n",
       "      <td>10.085809</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>961.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>45000.000000</td>\n",
       "      <td>10.714418</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>1764.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>76000.000000</td>\n",
       "      <td>11.238489</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>53.000000</td>\n",
       "      <td>2809.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>682000.000000</td>\n",
       "      <td>13.432785</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>4225.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         YEAR        INCWAGE  INCWAGE_log       EDUCDC       female  \\\n",
       "count  8143.0    8143.000000  8143.000000  8143.000000  8143.000000   \n",
       "mean   2021.0   63632.890826    10.561771    14.231610     0.481027   \n",
       "std       0.0   75031.705812     1.133858     3.023473     0.499671   \n",
       "min    2021.0      30.000000     3.401197     0.000000     0.000000   \n",
       "25%    2021.0   24000.000000    10.085809    12.000000     0.000000   \n",
       "50%    2021.0   45000.000000    10.714418    14.000000     0.000000   \n",
       "75%    2021.0   76000.000000    11.238489    16.000000     1.000000   \n",
       "max    2021.0  682000.000000    13.432785    22.000000     1.000000   \n",
       "\n",
       "               AGE       AGE_SQ        White        Black     hispanic  \\\n",
       "count  8143.000000  8143.000000  8143.000000  8143.000000  8143.000000   \n",
       "mean     41.526096  1898.076753     0.663269     0.081051     0.162348   \n",
       "std      13.178825  1104.537492     0.472621     0.272931     0.368792   \n",
       "min      18.000000   324.000000     0.000000     0.000000     0.000000   \n",
       "25%      31.000000   961.000000     0.000000     0.000000     0.000000   \n",
       "50%      42.000000  1764.000000     1.000000     0.000000     0.000000   \n",
       "75%      53.000000  2809.000000     1.000000     0.000000     0.000000   \n",
       "max      65.000000  4225.000000     1.000000     1.000000     1.000000   \n",
       "\n",
       "           married       NCHILD          VET        hsdip       coldip  \n",
       "count  8143.000000  8143.000000  8143.000000  8143.000000  8143.000000  \n",
       "mean      0.533833     0.823898     0.041754     0.541815     0.406607  \n",
       "std       0.498885     1.151690     0.200038     0.498279     0.491230  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "50%       1.000000     0.000000     0.000000     1.000000     0.000000  \n",
       "75%       1.000000     2.000000     0.000000     1.000000     1.000000  \n",
       "max       1.000000     9.000000     1.000000     1.000000     1.000000  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acs_data[[\"YEAR\", \"INCWAGE\", \"INCWAGE_log\", 'EDUCDC', 'female', 'AGE', 'AGE_SQ',\n",
    "          'White', 'Black', 'hispanic', 'married', 'NCHILD', 'VET', 'hsdip', 'coldip']].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Scatter plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    " lm_simple = lm().fit(acs_data[['EDUCDC']], acs_data[['INCWAGE_log']])\n",
    " simple_y_pred = lm_simple.predict(acs_data[['EDUCDC']])\n",
    " plt.scatter(acs_data[['EDUCDC']], acs_data[['INCWAGE_log']], color=\"black\")\n",
    " plt.plot(acs_data[['EDUCDC']], simple_y_pred, color=\"blue\", linewidth=3)\n",
    " plt.xlabel('Years of education')\n",
    " plt.ylabel('Log(Income)')\n",
    "\n",
    " plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Estimate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            INCWAGE_log   R-squared:                       0.283\n",
      "Model:                            OLS   Adj. R-squared:                  0.282\n",
      "Method:                 Least Squares   F-statistic:                     321.1\n",
      "Date:                Fri, 17 Feb 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:11:46   Log-Likelihood:                -11222.\n",
      "No. Observations:                8143   AIC:                         2.247e+04\n",
      "Df Residuals:                    8132   BIC:                         2.254e+04\n",
      "Df Model:                          10                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      5.6989      0.126     45.295      0.000       5.452       5.946\n",
      "EDUCDC         0.1043      0.004     28.120      0.000       0.097       0.112\n",
      "female        -0.4020      0.022    -18.563      0.000      -0.444      -0.360\n",
      "AGE            0.1603      0.006     26.028      0.000       0.148       0.172\n",
      "AGE_SQ        -0.0017   7.28e-05    -23.211      0.000      -0.002      -0.002\n",
      "White          0.0604      0.030      2.007      0.045       0.001       0.119\n",
      "Black         -0.2162      0.047     -4.610      0.000      -0.308      -0.124\n",
      "hispanic      -0.0073      0.036     -0.202      0.840      -0.078       0.064\n",
      "married        0.1894      0.025      7.562      0.000       0.140       0.239\n",
      "NCHILD        -0.0022      0.011     -0.206      0.837      -0.023       0.019\n",
      "VET            0.0687      0.054      1.267      0.205      -0.038       0.175\n",
      "==============================================================================\n",
      "Omnibus:                     2586.782   Durbin-Watson:                   1.864\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            11798.652\n",
      "Skew:                          -1.483   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.096   Cond. No.                     2.62e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 2.62e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "result = smf.ols('INCWAGE_log ~ EDUCDC + female + AGE + AGE_SQ + White + Black + hispanic + married + NCHILD + VET', data = acs_data)\n",
    "print(result.fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) What fraction of the variation in log wages does the model explain?\n",
    "\n",
    "Answer: *The value of the R squared: 0.264*\n",
    "\n",
    "(b) Test the hypothesis that [...]:\n",
    "\n",
    "Answer: *This hypothesis is being tested in the default summary under the F-statistic and Prob(F-Statistic). In this case, the p-value is zero. Therefore, we can reject the null at the 90, 95 and 99% of confidence.*\n",
    "\n",
    "(c) What is the return to an additional year of education? Is this statistically significant? Is it practically significant? Briefly explain\n",
    "\n",
    "Answer *The coefficient of years of education is 0.0903. Since the dependent variable is in logs, an additional year of education is associated with an increase of about 9.45% (= e<sup>0.0903</sup> âˆ’1) in income.*\n",
    "\n",
    "(d) At what age does the model predict an individual will achieve the highest wage?\n",
    "\n",
    "Answer: *Let's take the derivative of Age*\n",
    "\n",
    "        d(ols)/d(AGE) = 0.1571 + 2 * - 0.0016 * AGE\n",
    "        d(ols)/d(AGE) = 0.1571 - 0.0032 * AGE\n",
    "\n",
    "*Since we know that our function is concave, our max will be located whenever the derivative is equal to zero. In other words:*\n",
    "\n",
    "        0 = 0.1571 - 0.0032 * AGE\n",
    "        0.0032 * AGE = 0.1571\n",
    "        AGE = 0.1571/0.0032 = 49.09\n",
    "\n",
    "*Another way is the brute-force way:*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age with highest income: 49\n"
     ]
    }
   ],
   "source": [
    "highest_income = 0\n",
    "for current_age in range(100):\n",
    "    # Current income for age = current_age\n",
    "    current_income = 0.1571 - 0.0032*current_age\n",
    "    if highest_income > current_income:\n",
    "        print(\"Age with highest income:\", current_age - 1)\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Doesn't work with decimals but it's not so bad*\n",
    "\n",
    "(e) Does the model predict that men or women will have higher wages, all else equal? Briefly explain why we might observe this pattern in the data\n",
    "\n",
    "*The female coefficient is negative. This suggests women earn about 30% less than men*\n",
    "\n",
    "*All else in the model equal, women earn 70.5% of what men earn since 100(e<sup>-0.3496</sup>-1)  is roughly -29.5%. There are many factors left out of the model such as occupational choice, preference over leisure, and willingness to negotiate compensation. However, the modelâ€™s result of women earning less than men with all other attributes of the model being equal is consistent with studies that control for much more and still find women earning less than men albeit to a lesser degree.*\n",
    "\n",
    "(f) Interpret the coefficients on the white and black, and its significance\n",
    "\n",
    "*First, itâ€™s important to establish the baseline group for comparison. The baseline group consists of people who either did not check any of the boxes or do not identify as white, black, or Hispanic. So compared to this baseline group, a person from a particular demographic J earns 100(e<sup>Î²J</sup>-1) of what a baseline group member would earn with all else in the model equal. So all else in the model equal, a white person earns 103.33% (e<sup>0.0328</sup>-1=3.33%) of what a baseline group member earns. For a black person, itâ€™s 82.73% 100(e<sup> -0.1896 </sup>-1=-17.27%).*\n",
    "\n",
    "*Only the estimate for black is statistically significant, associated p-value is 0.00*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_reg_line(data, line_color, label):\n",
    "    '''\n",
    "    Get scatter plot with fitted OLS regression line\n",
    "    Input: data- data frame\n",
    "    line_color(str)- string for line color\n",
    "    label(str)- line label name\n",
    "    Output: Plot\n",
    "    '''\n",
    "    y = data[['INCWAGE_log']].values\n",
    "    X = data[['EDUCDC' ]].values\n",
    "    y_pred = lm().fit(X, y).predict(X)\n",
    "\n",
    "    return plt.plot(X, y_pred, color= line_color, linewidth=3, label = label)\n",
    "\n",
    "\n",
    "\n",
    "plt.scatter(acs_data[['EDUCDC']], acs_data[[\"INCWAGE_log\"]], color=\"black\")\n",
    "get_reg_line(acs_data[acs_data['hsdip'] == 1], \"blue\", \"High-school diploma\")\n",
    "get_reg_line(acs_data[acs_data['EDUCDC'] < 12], \"red\", \"No High-school diploma\")\n",
    "get_reg_line(acs_data[acs_data['coldip'] == 1], \"purple\", \"College degree\")\n",
    "plt.xlabel('Years of education')\n",
    "plt.title('Relationship between education and wage')\n",
    "plt.legend()\n",
    "plt.ylabel('Log(Income)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. \n",
    "\n",
    "Answer: *There are many ways to modify the model. One such way is to allow (i) different intercepts for the three groups (no degree, high school degree, college degree) and (ii) different slopes for the three groups. That is,*\n",
    "\n",
    "ln(incwage) = Î²0+Î³<sub>1</sub>hsdip+Î³<sub>2</sub>coldip+Î³<sub>3</sub>hsdipÂ·educdc+Î³<sub>4</sub>coldipÂ·educdc+...\n",
    "\n",
    "*where hsdip and coldip are indicator functions for whether an individual is a high school graduate or a college graduate. In the ellipsis are controls from the original model as well as the error term*\n",
    "\n",
    "### 6. Estimate the model you proposed in the previous question and report your results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            INCWAGE_log   R-squared:                       0.302\n",
      "Model:                            OLS   Adj. R-squared:                  0.301\n",
      "Method:                 Least Squares   F-statistic:                     250.9\n",
      "Date:                Fri, 17 Feb 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:11:46   Log-Likelihood:                -11115.\n",
      "No. Observations:                8143   AIC:                         2.226e+04\n",
      "Df Residuals:                    8128   BIC:                         2.236e+04\n",
      "Df Model:                          14                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=======================================================================================\n",
      "                          coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------------\n",
      "Intercept               6.7842      0.149     45.658      0.000       6.493       7.075\n",
      "hsdip                  -0.6967      0.216     -3.233      0.001      -1.119      -0.274\n",
      "coldip                 -0.7336      0.218     -3.359      0.001      -1.162      -0.306\n",
      "EDUCDC                  0.0128      0.011      1.180      0.238      -0.008       0.034\n",
      "hsdip_inter_educdc      0.0693      0.019      3.701      0.000       0.033       0.106\n",
      "coldip_inter_educdc     0.0907      0.016      5.646      0.000       0.059       0.122\n",
      "female                 -0.4047      0.021    -18.881      0.000      -0.447      -0.363\n",
      "AGE                     0.1488      0.006     24.274      0.000       0.137       0.161\n",
      "AGE_SQ                 -0.0016   7.25e-05    -21.524      0.000      -0.002      -0.001\n",
      "White                   0.0899      0.030      3.013      0.003       0.031       0.148\n",
      "Black                  -0.1604      0.046     -3.453      0.001      -0.252      -0.069\n",
      "hispanic               -0.0091      0.036     -0.256      0.798      -0.079       0.061\n",
      "married                 0.1680      0.025      6.780      0.000       0.119       0.217\n",
      "NCHILD                 -0.0026      0.010     -0.249      0.803      -0.023       0.018\n",
      "VET                     0.0996      0.054      1.858      0.063      -0.005       0.205\n",
      "==============================================================================\n",
      "Omnibus:                     2804.569   Durbin-Watson:                   1.880\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            13758.157\n",
      "Skew:                          -1.595   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.511   Cond. No.                     5.06e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.06e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "result = smf.ols('INCWAGE_log ~ hsdip + coldip + EDUCDC + hsdip_inter_educdc + coldip_inter_educdc + female + AGE + AGE_SQ + White + Black + hispanic + married + NCHILD + VET', data = acs_data)\n",
    "print(result.fit().summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(a) What fraction of the variation in log wages does the model explain? How does this  compare to the model you estimated in question 3?*\n",
    "\n",
    "*The variation in the log of wages explained by the model is $R^2 = 0.286$, this is greater than the $R^2=0.264$ of the model estimated in question 3.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(b) Predict the wages of an 22 year old, female individual (who is neither white, black, nor Hispanic, is not married, has no children, and is not a veteran) with a high school diploma and an all else equal individual with a college diploma. Assume that it takes someone 12 years to graduate high school and 16 years to graduate college.*\n",
    "\n",
    "*The predicted wages for an with individual with that characteristics and a HS degree are approximately $10,911.87, while the predicted wages for an individual with a college degree are approximately $18,924.54*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wage with HS degree: 9772.042974449947\n",
      "Wage with college degree: 18411.02083136736\n"
     ]
    }
   ],
   "source": [
    "# High School degree\n",
    "dict_hs = {'female': [1], 'AGE' : [22] ,'AGE_SQ' : [484], 'hsdip': [1], 'coldip':[0],\n",
    " 'Black': [0], 'hispanic':[0], 'NCHILD': [0], 'married': [0], 'VET':[0], 'EDUCDC':[12], \n",
    " 'hsdip_inter_educdc': [12], 'coldip_inter_educdc': [0], 'White': [0]}\n",
    "df_pred = pd.DataFrame(data=dict_hs)\n",
    "prediction1 = result.fit().get_prediction(df_pred)\n",
    "prediction1 = prediction1.summary_frame(alpha=0.05)\n",
    "prediction1_wage = np.exp(prediction1['mean'].values[0])\n",
    "print(f'Wage with HS degree: {prediction1_wage}')\n",
    "\n",
    "# College degree\n",
    "dict_cd = {'female': [1], 'AGE' : [22] ,'AGE_SQ' : [484], 'hsdip': [0], 'coldip':[1],\n",
    " 'Black': [0], 'hispanic':[0], 'NCHILD': [0], 'married': [0], 'VET':[0], 'EDUCDC':[16], \n",
    " 'hsdip_inter_educdc': [0], 'coldip_inter_educdc': [16], 'White': [0]}\n",
    "df_pred = pd.DataFrame(data=dict_cd)\n",
    "prediction2 = result.fit().get_prediction(df_pred)\n",
    "prediction2 = prediction2.summary_frame(alpha=0.05)\n",
    "prediction2_wage = np.exp(prediction2['mean'].values[0])\n",
    "print(f'Wage with college degree: {prediction2_wage}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*(c) The President is concerned that citizens will be harmed (and voters unhappy) if the predictions from your model turn out to be wrong. She wants to know how confident you are in your predictions. Briefly explain.*\n",
    "\n",
    "\n",
    "*Open-ended question. Full credit if explanation is based on the strengths or weaknesses of the model or the estimation results.*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. There are many ways that this model could be improved. How would you do things differently if you were asked to predict the returns to education given the data available (without any other stipulations)? Try fitting some different models and report the results of the model that best predicts log wages that you can come up with. Use adjusted R2 as your measure of the model that produces the best prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YEAR', 'SAMPLE', 'SERIAL', 'CBSERIAL', 'HHWT', 'CLUSTER', 'STRATA',\n",
       "       'GQ', 'PERNUM', 'PERWT', 'NCHILD', 'NCHLT5', 'SEX', 'AGE', 'MARST',\n",
       "       'RACE', 'RACED', 'HISPAN', 'HISPAND', 'EDUC', 'EDUCD', 'EMPSTAT',\n",
       "       'EMPSTATD', 'INCWAGE', 'VETSTAT', 'VETSTATD', 'EDUCDC', 'hsdip',\n",
       "       'coldip', 'White', 'Black', 'hispanic', 'married', 'female', 'VET',\n",
       "       'hsdip_inter_educdc', 'coldip_inter_educdc', 'AGE_SQ', 'INCWAGE_log'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examining all columns\n",
    "acs_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R2 for model:  0.12647115702715728\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            INCWAGE_log   R-squared:                       0.127\n",
      "Model:                            OLS   Adj. R-squared:                  0.126\n",
      "Method:                 Least Squares   F-statistic:                     590.4\n",
      "Date:                Fri, 17 Feb 2023   Prob (F-statistic):          3.67e-240\n",
      "Time:                        14:11:46   Log-Likelihood:                -12025.\n",
      "No. Observations:                8143   AIC:                         2.406e+04\n",
      "Df Residuals:                    8140   BIC:                         2.408e+04\n",
      "Df Model:                           2                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     10.0427      0.052    194.213      0.000       9.941      10.144\n",
      "hsdip          0.2049      0.054      3.786      0.000       0.099       0.311\n",
      "coldip         1.0036      0.055     18.284      0.000       0.896       1.111\n",
      "==============================================================================\n",
      "Omnibus:                     2362.944   Durbin-Watson:                   1.858\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             8706.325\n",
      "Skew:                          -1.420   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.194   Cond. No.                         9.37\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model 1\n",
    "model1 = smf.ols('INCWAGE_log ~ hsdip + coldip', data=acs_data).fit() \n",
    "print(\"Adjusted R2 for model: \", model1.rsquared_adj)\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R2 for model:  0.16554784386963584\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            INCWAGE_log   R-squared:                       0.166\n",
      "Model:                            OLS   Adj. R-squared:                  0.166\n",
      "Method:                 Least Squares   F-statistic:                     324.1\n",
      "Date:                Fri, 17 Feb 2023   Prob (F-statistic):          1.81e-317\n",
      "Time:                        14:11:46   Log-Likelihood:                -11838.\n",
      "No. Observations:                8143   AIC:                         2.369e+04\n",
      "Df Residuals:                    8137   BIC:                         2.373e+04\n",
      "Df Model:                           5                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept     10.1527      0.053    193.196      0.000      10.050      10.256\n",
      "hsdip          0.2074      0.054      3.867      0.000       0.102       0.312\n",
      "coldip         1.0094      0.055     18.488      0.000       0.902       1.116\n",
      "female        -0.4041      0.023    -17.520      0.000      -0.449      -0.359\n",
      "White          0.1409      0.027      5.194      0.000       0.088       0.194\n",
      "Black         -0.1579      0.047     -3.394      0.001      -0.249      -0.067\n",
      "==============================================================================\n",
      "Omnibus:                     2515.159   Durbin-Watson:                   1.853\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10041.436\n",
      "Skew:                          -1.487   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.555   Cond. No.                         11.5\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "model2 = smf.ols('INCWAGE_log ~ hsdip + coldip + female + White + Black', data=acs_data).fit() \n",
    "print(\"Adjusted R2 for model: \", model2.rsquared_adj)\n",
    "print(model2.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R2 for model:  0.1731113322827299\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            INCWAGE_log   R-squared:                       0.174\n",
      "Model:                            OLS   Adj. R-squared:                  0.173\n",
      "Method:                 Least Squares   F-statistic:                     285.1\n",
      "Date:                Fri, 17 Feb 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:11:46   Log-Likelihood:                -11800.\n",
      "No. Observations:                8143   AIC:                         2.361e+04\n",
      "Df Residuals:                    8136   BIC:                         2.366e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      9.7228      0.072    135.004      0.000       9.582       9.864\n",
      "hsdip         -0.2130      0.072     -2.956      0.003      -0.354      -0.072\n",
      "coldip         0.3243      0.096      3.385      0.001       0.137       0.512\n",
      "female        -0.4108      0.023    -17.883      0.000      -0.456      -0.366\n",
      "White          0.1319      0.027      4.880      0.000       0.079       0.185\n",
      "Black         -0.1635      0.046     -3.529      0.000      -0.254      -0.073\n",
      "EDUCDC         0.0665      0.008      8.685      0.000       0.051       0.081\n",
      "==============================================================================\n",
      "Omnibus:                     2559.933   Durbin-Watson:                   1.853\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10387.529\n",
      "Skew:                          -1.509   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.637   Cond. No.                         152.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model 3\n",
    "model3 = smf.ols('INCWAGE_log ~ hsdip + coldip + female + White + Black + EDUCDC', data=acs_data).fit() \n",
    "print(\"Adjusted R2 for model: \", model3.rsquared_adj)\n",
    "print(model3.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R2 for model:  0.2135158001352515\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            INCWAGE_log   R-squared:                       0.214\n",
      "Model:                            OLS   Adj. R-squared:                  0.214\n",
      "Method:                 Least Squares   F-statistic:                     369.4\n",
      "Date:                Fri, 17 Feb 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:11:46   Log-Likelihood:                -11596.\n",
      "No. Observations:                8143   AIC:                         2.321e+04\n",
      "Df Residuals:                    8136   BIC:                         2.326e+04\n",
      "Df Model:                           6                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      9.7418      0.054    179.592      0.000       9.635       9.848\n",
      "hsdip          0.2497      0.052      4.793      0.000       0.148       0.352\n",
      "coldip         1.0359      0.053     19.539      0.000       0.932       1.140\n",
      "female        -0.4142      0.022    -18.495      0.000      -0.458      -0.370\n",
      "White          0.0743      0.027      2.805      0.005       0.022       0.126\n",
      "Black         -0.2064      0.045     -4.565      0.000      -0.295      -0.118\n",
      "AGE_SQ         0.0002   1.02e-05     22.300      0.000       0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     2704.126   Durbin-Watson:                   1.850\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12140.361\n",
      "Skew:                          -1.564   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.099   Cond. No.                     1.72e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.72e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Model 4\n",
    "model4 = smf.ols('INCWAGE_log ~ hsdip + coldip + female + White + Black + AGE_SQ ', data=acs_data).fit() \n",
    "print(\"Adjusted R2 for model: \", model4.rsquared_adj)\n",
    "print(model4.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R2 for model:  0.23245534613223184\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            INCWAGE_log   R-squared:                       0.233\n",
      "Model:                            OLS   Adj. R-squared:                  0.232\n",
      "Method:                 Least Squares   F-statistic:                     353.3\n",
      "Date:                Fri, 17 Feb 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:11:46   Log-Likelihood:                -11496.\n",
      "No. Observations:                8143   AIC:                         2.301e+04\n",
      "Df Residuals:                    8135   BIC:                         2.306e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "Intercept      9.6635      0.054    179.386      0.000       9.558       9.769\n",
      "hsdip          0.2543      0.051      4.941      0.000       0.153       0.355\n",
      "coldip         0.9966      0.052     19.000      0.000       0.894       1.099\n",
      "female        -0.3933      0.022    -17.737      0.000      -0.437      -0.350\n",
      "White          0.0567      0.026      2.165      0.030       0.005       0.108\n",
      "Black         -0.1431      0.045     -3.187      0.001      -0.231      -0.055\n",
      "AGE_SQ         0.0002   1.06e-05     16.739      0.000       0.000       0.000\n",
      "married        0.3394      0.024     14.204      0.000       0.293       0.386\n",
      "==============================================================================\n",
      "Omnibus:                     2715.608   Durbin-Watson:                   1.858\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12360.181\n",
      "Skew:                          -1.566   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.159   Cond. No.                     1.72e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.72e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Model 5\n",
    "model5 = smf.ols('INCWAGE_log ~ hsdip + coldip + female + White + Black + AGE_SQ + married ', data=acs_data).fit() \n",
    "print(\"Adjusted R2 for model: \", model5.rsquared_adj)\n",
    "print(model5.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R2 for model:  0.19646808604798882\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            INCWAGE_log   R-squared:                       0.197\n",
      "Model:                            OLS   Adj. R-squared:                  0.196\n",
      "Method:                 Least Squares   F-statistic:                     249.8\n",
      "Date:                Fri, 17 Feb 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:11:47   Log-Likelihood:                -11682.\n",
      "No. Observations:                8143   AIC:                         2.338e+04\n",
      "Df Residuals:                    8134   BIC:                         2.345e+04\n",
      "Df Model:                           8                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept           10.0984      0.054    186.177      0.000       9.992      10.205\n",
      "hsdip                0.2383      0.053      4.498      0.000       0.134       0.342\n",
      "coldip               0.9970      0.054     18.423      0.000       0.891       1.103\n",
      "female              -0.3845      0.023    -16.965      0.000      -0.429      -0.340\n",
      "White               -0.1040      0.033     -3.168      0.002      -0.168      -0.040\n",
      "Black               -0.2455      0.054     -4.567      0.000      -0.351      -0.140\n",
      "white_married        0.4741      0.028     16.771      0.000       0.419       0.530\n",
      "black_married        0.3707      0.086      4.299      0.000       0.202       0.540\n",
      "hispanic_married     0.1470      0.047      3.097      0.002       0.054       0.240\n",
      "==============================================================================\n",
      "Omnibus:                     2533.911   Durbin-Watson:                   1.866\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            10516.468\n",
      "Skew:                          -1.484   Prob(JB):                         0.00\n",
      "Kurtosis:                       7.710   Cond. No.                         12.7\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model 6 with interaction terms\n",
    "acs_data['white_married'] = acs_data['White'] * acs_data['married']\n",
    "acs_data['black_married'] = acs_data['Black'] * acs_data['married']\n",
    "acs_data['hispanic_married'] = acs_data['hispanic'] * acs_data['married']\n",
    "\n",
    "model6 = smf.ols('INCWAGE_log ~ hsdip + coldip + female + White + Black + white_married + black_married + hispanic_married', data=acs_data).fit() \n",
    "print(\"Adjusted R2 for model: \", model6.rsquared_adj)\n",
    "print(model6.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R2 for model:  0.24176574026011655\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            INCWAGE_log   R-squared:                       0.243\n",
      "Model:                            OLS   Adj. R-squared:                  0.242\n",
      "Method:                 Least Squares   F-statistic:                     289.5\n",
      "Date:                Fri, 17 Feb 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:11:47   Log-Likelihood:                -11446.\n",
      "No. Observations:                8143   AIC:                         2.291e+04\n",
      "Df Residuals:                    8133   BIC:                         2.298e+04\n",
      "Df Model:                           9                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "====================================================================================\n",
      "                       coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------\n",
      "Intercept            9.3428      0.063    148.678      0.000       9.220       9.466\n",
      "hsdip                0.2704      0.051      5.253      0.000       0.170       0.371\n",
      "coldip               1.0142      0.053     19.290      0.000       0.911       1.117\n",
      "female              -0.4021      0.022    -18.253      0.000      -0.445      -0.359\n",
      "White               -0.0840      0.032     -2.632      0.009      -0.147      -0.021\n",
      "Black               -0.2551      0.052     -4.885      0.000      -0.357      -0.153\n",
      "white_married        0.3013      0.029     10.551      0.000       0.245       0.357\n",
      "black_married        0.1976      0.084      2.349      0.019       0.033       0.362\n",
      "hispanic_married     0.0641      0.046      1.386      0.166      -0.027       0.155\n",
      "AGE                  0.0194      0.001     22.067      0.000       0.018       0.021\n",
      "==============================================================================\n",
      "Omnibus:                     2750.393   Durbin-Watson:                   1.862\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12808.391\n",
      "Skew:                          -1.580   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.269   Cond. No.                         363.\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "# Model 7 with interaction terms\n",
    "model7 = smf.ols('INCWAGE_log ~ hsdip + coldip + female + White + Black + white_married + black_married + hispanic_married + AGE', data=acs_data).fit() \n",
    "print(\"Adjusted R2 for model: \", model7.rsquared_adj)\n",
    "print(model7.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjusted R2 for model:  0.2271882053650799\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:            INCWAGE_log   R-squared:                       0.228\n",
      "Model:                            OLS   Adj. R-squared:                  0.227\n",
      "Method:                 Least Squares   F-statistic:                     342.9\n",
      "Date:                Fri, 17 Feb 2023   Prob (F-statistic):               0.00\n",
      "Time:                        14:11:47   Log-Likelihood:                -11524.\n",
      "No. Observations:                8143   AIC:                         2.306e+04\n",
      "Df Residuals:                    8135   BIC:                         2.312e+04\n",
      "Df Model:                           7                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "=================================================================================\n",
      "                    coef    std err          t      P>|t|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "Intercept         9.7983      0.054    181.534      0.000       9.693       9.904\n",
      "hsdip             0.2506      0.052      4.854      0.000       0.149       0.352\n",
      "coldip            1.0089      0.053     19.179      0.000       0.906       1.112\n",
      "female           -0.4014      0.022    -18.062      0.000      -0.445      -0.358\n",
      "White            -0.1151      0.031     -3.759      0.000      -0.175      -0.055\n",
      "Black            -0.2043      0.045     -4.557      0.000      -0.292      -0.116\n",
      "white_married     0.3442      0.029     12.039      0.000       0.288       0.400\n",
      "AGE_SQ            0.0002   1.04e-05     18.755      0.000       0.000       0.000\n",
      "==============================================================================\n",
      "Omnibus:                     2718.814   Durbin-Watson:                   1.861\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            12379.305\n",
      "Skew:                          -1.568   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.162   Cond. No.                     1.72e+04\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 1.72e+04. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    }
   ],
   "source": [
    "# Model 8 with interaction terms\n",
    "model8 = smf.ols('INCWAGE_log ~ hsdip + coldip + female + White + Black + white_married + AGE_SQ', data=acs_data).fit() \n",
    "print(\"Adjusted R2 for model: \", model8.rsquared_adj)\n",
    "print(model8.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Inferences:**\n",
    "1. In our trails, the maximum Adjusted R2 = '0.022621371990750205' is acheived for Model 5 regressing 'INCWAGE_log' with 'hsdip + coldip + female + White + Black + AGE_SQ + married'.     \n",
    "2. Education level, Gender, Race, Age and Marital status are key determinants for wage levels. Removing these terms in Model 9 resulted in decrease of Adjusted R2 to '0.002517230323518249'.   \n",
    "3. We can experiement with more models.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "a63e1f615196db66ca264332955e6a0bb5ae024218425d84f3a82744815494ae"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
